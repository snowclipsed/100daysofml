{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center> 100 Days of Machine Learning - Day 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 days of machine learning is a tech challenge where the participants spend 100 continuous days studying, learning and coding machine learning concepts. It involves dedicating a certain amount of time each day to engage in ML-related activities, such as reading books, watching tutorials, completing online courses, working on projects, or participating in coding exercises. The goal is to develop a consistent learning habit and make significant progress in ML skills over the course of 100 days."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "A support vector machine or SVM is a supervised learning algorithm used for classification tasks. It works on the principle of creating a \"decision boundary\" that can seperate an n-dimensional space into classes. Once the space is split into classes, it is easy to predict where an external or unseen data point lies amongst those classes.\n",
    "\n",
    "This decision boundary that divides the space is called a \"Hyperplane\" and the points closest to the hyperplane are called the support vectors. The distance between the hyperplane and the support vector is called a \"margin\".\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the SVM algorithm is to maximize the margin or the distance between the hyperplane and the support vectors in order to find the optimal hyperplane that can classify the data points correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperplane\n",
    "\n",
    "A hyperplane is an (n-1) dimensional subspace which acts as the decision boundary between classes in an SVM, the optimization of which will give us seperable classes. Breaking the previous complicated line down - hyperplane being (n-1) dimensions refers to it having one less dimension than the amount of feature dimensions (n) - to simplify further, if the features are 2, then we are dealing with a 2 dimensional space and the hyperplane will be 2 - 1 = 1 dimensional, which is a line. This is exactly what we see in the image above. Similarly if the feature dimensions are a 3D space, the hyperplane will be a 2D plane. \n",
    "\n",
    "A hyperplane is said to be an optimized hyperplane when the margin from the support vectors is optimized.\n",
    "\n",
    "A hyperplane is called a seperating hyperplane when it can successfully divides groups of data points which are linearly seperable in an ideal scenario. By linearly seperable, we mean a straight line can divide the two classes. \n",
    "\n",
    "<img src = \"https://miro.medium.com/v2/resize:fit:828/format:webp/1*bXbbnOt2rsnbIoL_2FxHnA.png\" width = 500 align = \"center\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linearly Seperable Data.\n",
    "\n",
    "In an ideal scenario, the datapoints of different classes are scattered in such a way that they are linearly seperable. However, the ideal scenario does not usually occur in data and the classes are not directly linearly seperable.\n",
    "\n",
    "In such cases, we employ two methods to try and classify the data : \n",
    "\n",
    "- Soft Margin Approach\n",
    "- Kernel Trick\n",
    "\n",
    "\n",
    "This will be convered on [Day 7 SVM](https://github.com/snowclipsed/100daysofml/blob/main/Day%207/Day%207%20SVM.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46aba852",
   "metadata": {},
   "source": [
    "<h1 align = center> 100 Days of Machine Learning - Day 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec6f2690",
   "metadata": {},
   "source": [
    "100 days of machine learning is a tech challenge where the participants spend 100 continuous days studying, learning and coding machine learning concepts. It involves dedicating a certain amount of time each day to engage in ML-related activities, such as reading books, watching tutorials, completing online courses, working on projects, or participating in coding exercises. The goal is to develop a consistent learning habit and make significant progress in ML skills over the course of 100 days."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "703d1dc6",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Linear Regression\n",
    "2. Cost Function concept"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21747601",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear Regression is one of the most utilized and the most simple machine learning algorithms. In Linear Regression, we fit a straight line to a set of points in order to solve for some target variable. This line is called the regression line and it is a set of points which can best represent all the points scattered on the graph.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72bd7776",
   "metadata": {},
   "source": [
    "<img src = \"https://www.joshuapkeller.com/page/introregression/IntroRegression_files/figure-html/g-penguin-flip-mass-lm1b-1.png\" height = 300px align = 'center'>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b853d323",
   "metadata": {},
   "source": [
    "Linear regression works through a supervised approach. This means we provide the algorithm with a 'training set' containing inputs and the right answers for those inputs, and the model learns to fit a line by using those inputs and right answers as reference.\n",
    "\n",
    "\n",
    "$$\n",
    "x \\rightarrow f(x) \\rightarrow \\hat{y}\n",
    "$$\n",
    "\n",
    "The output of the linear regression model is calculated by looking up the value of ŷ by inputting the value of x.\n",
    "\n",
    "## Types of Linear Regression\n",
    "\n",
    "There are various types of Linear regression approaches:\n",
    "\n",
    "1. Simple Linear Regression\n",
    "\n",
    "2. Multivariable Linear Regression\n",
    "\n",
    "3. Polynomial Regression\n",
    "\n",
    "4. Ridge Regression\n",
    "\n",
    "5. Lasso and Elastic Net Regression\n",
    "\n",
    "Our focus for today will be on simple linear regression (let's call it SLR for short)\n",
    "\n",
    "## Simple Linear Regression (SLR)\n",
    "\n",
    "SLR is a linear regression model where the dependent variable or the output variable like car prices is affected only by one single independent variable or feature, like say - horsepower.\n",
    "\n",
    "For SLR, the regression line is a single straight line that needs to best fit the represented points on a graph. The formular to perform SLR is based off the formula for a straight line : \n",
    "\n",
    "$$\n",
    "f (x) = wx + b\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab3866e6",
   "metadata": {},
   "source": [
    "Where w and b are the weights and biases for SLR. The weight acts as the slope of the line, and the bias acts as the y - intercept."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aed5596d",
   "metadata": {},
   "source": [
    "# Cost Function or Loss function\n",
    "\n",
    "A cost function is a method to optimize the fitting of the model to our training set. This is done by minimizing the cost/loss between the target ground truth values and the actual value. The concept of the cost function is universal to supervised learning algorithms, with it being an effective way to solve for the target variables. Given that, there are many kinds of cost functions from simple to complex, and the choice of cost function can greatly affect the output and/or the performance of the trained model.\n",
    "\n",
    "There are many popular cost functions such as :\n",
    "\n",
    "1. Mean-Squared Error (MSE)\n",
    "2. Mean Absolute Error (MAE)\n",
    "3. Cross-Entropy Loss\n",
    "4. Hinge Loss\n",
    "5. Mean-Squared Log Error (MSLE)\n",
    "6. Gini Index\n",
    "\n",
    "and many more - the list goes on, and many state-of-the-art algorithms often make their own cost functions that can optimize for their approach well. Each type of cost function has their own strengths and weaknesses, and no cost function is not objectively better to use in every scenario.\n",
    "\n",
    "Today, we will look at MSE, which is a cost function commonly used in SLR scenarios.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c64caa9f",
   "metadata": {},
   "source": [
    "## Mean-Squared Error\n",
    "\n",
    "Mean-Squared Error or MSE is defined as the average squared difference between the predicted (ŷ) values and the actual (y) ground truth values. \n",
    "\n",
    "Then we solve for ŷ using our current regression line : \n",
    "\n",
    "$$\n",
    "\n",
    "\\hat{y} = f(x) = wx + b\n",
    "\n",
    "$$\n",
    "\n",
    "Then, once ŷ is obtained, we find the square of the difference between ŷ and y for the same x value, and do this for every single point in the dataset. Then, we take an average of all those values, which gives us our MSE.\n",
    "\n",
    "$$\n",
    "\n",
    "\\frac{\\sum{(y - \\hat{y})^2}}{n}\n",
    "\n",
    "$$\n",
    "\n",
    "Where n is the number of total points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5920d08",
   "metadata": {},
   "source": [
    "In SLR (and basically any other supervised algorithm), the goal is to minimize the cost or loss function. It is a good for LR models since it penalizes larger errors much more, because of the squared value in the function. Squaring of the value in MSE always results in a net positive value, hence a larger MSE means a larger error and a worse fit of the regression line to the data. Conversely, if the MSE is smaller, the line is well fit to the training data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c995a2a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

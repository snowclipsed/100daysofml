{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center> 100 Days of Machine Learning - Day 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 days of machine learning is a tech challenge where the participants spend 100 continuous days studying, learning and coding machine learning concepts. It involves dedicating a certain amount of time each day to engage in ML-related activities, such as reading books, watching tutorials, completing online courses, working on projects, or participating in coding exercises. The goal is to develop a consistent learning habit and make significant progress in ML skills over the course of 100 days."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. Gradient Descent\n",
    "2. Learning Rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "\n",
    "Gradient Descent or the gradient descent function is an optimization algorithm that is used to minimize the value of a function, typically a loss function in a machine learning environment. This is achieved by the algorithm adjusting various parameters inside the model and helps to \"train\" the model.\n",
    "\n",
    "Gradient descent is called so because it does a stepwise decent on the cost function gradient towards the local or global minima.\n",
    "\n",
    "Gradient descent is not a single algorithm, it is a collection of algorithms that are used in different scenarios variatingly just like the cost function, but the basic principle of all gradient descent approaches is the same.\n",
    "\n",
    "Here's how gradient descent works in general : \n",
    "\n",
    " - Initialize the parameters of the model with some values.\n",
    " - Calculate gradient loss.\n",
    " - Update the current parameters by subtracting a small amount or a fractional amount of the gradient based on the learning rate.\n",
    " - Repeat till a minima or convergence is reached or a specific number of iterations takes place. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\n",
    "w = w - \\alpha \\frac{{d}}{{dx}} J(w,b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where α is the learning rate in the equation, J(w,b) is the cost function of f(x)\n",
    "\n",
    "\n",
    "this can be interpreted as : \n",
    "\n",
    "$$ \\frac{1}{n} = \\sum (f_{(w,b)}(x^{(i)}) - y^{(i)})(x^{(i)})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate (α)\n",
    "\n",
    "Learning Rate of an ML model is a hyperparameter which controls the step size of gradient descent when updating the parameters of the model. It controls the rate at which the parameters are adjusted from the calculated gradients of the loss function.\n",
    "\n",
    "Setting an optimal learning rate is crucial, since different learning rates can yield different outcomes : \n",
    "\n",
    " - If α is too high, the algorithm might overshoot the local minima and fail to properly converge or keep oscillating outside the local minima.\n",
    " - If α is too low, the gradient descent step will be too small and the algorithm will converge very slowly and result in a very high amount of processing time to find the local minima and optimize the parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate of the model can be both fixed and dynamic. In simpler models like LR, the value of α is kept fixed. \n",
    "\n",
    "Even when α is fixed, the gradient of the cost function will allow for dynamic steps to be taken during gradient descent. This is because as we travel down the slope through multiple steps, the value of the gradient itself becomes small, resulting in a smaller value of $$ \\alpha \\frac{d}{dw} J(w,b) $$\n",
    "\n",
    "\n",
    "This leads to the step size getting smaller as we approach the local minima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

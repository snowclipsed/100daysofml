{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = center> 100 Days of Machine Learning - Day 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 days of machine learning is a tech challenge where the participants spend 100 continuous days studying, learning and coding machine learning concepts. It involves dedicating a certain amount of time each day to engage in ML-related activities, such as reading books, watching tutorials, completing online courses, working on projects, or participating in coding exercises. The goal is to develop a consistent learning habit and make significant progress in ML skills over the course of 100 days."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- Decision Trees\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision Trees (DTs) are supervised learning algorithms. They are used for classification as well as regression tasks. As their name suggests, Decision *Trees* have a tree-like structure which comprises of root node, branch nodes and leaf nodes. This structure is heirarichal in nature.\n",
    "\n",
    "<img src = \"https://www.mastersindatascience.org/wp-content/uploads/sites/54/2022/05/tree-graphic.jpg\" height = 500px>\n",
    "\n",
    "The approach behind decision trees is basic but is really effective for a lot of scenarios. A decision tree splits a problem into a number of decisions based on the input features and the target variable. These splits are represented by the root node splitting into several branch nodes, and those branch nodes splitting even further till a leaf node or output is met. This is similar to a biological tree where water from the soil starts from the roots, is transported into either branches depending on where the water is needed, and ends up in a leaf for photosynthesis.\n",
    "\n",
    "## Components of a Decision Tree\n",
    "\n",
    "A decision tree has several components like Root node, Branches, Decision Nodes and Leaf nodes - let's discuss them one by one.\n",
    "\n",
    "- Root Node : A root node is the node/point of origin for the entire decision tree. A root node represents the entire population sample/dataset and the branch nodes originating from the root node then divide this dataset into 2 or more subsets.\n",
    "\n",
    "- Decision Node : A decision node is one that symbolizes a choice regarding a specific input feature or question asked. There may be two or more choice sprouting from such a node.\n",
    "\n",
    "- Branch : A branch is a section of a tree that is formed by \"splitting\" the tree from a decision node or a root node.\n",
    "\n",
    "- Leaf Node : Also called a \"terminal\" node, it is a node that does not have any child node ; i.e. ; it does not split into branches/further nodes. The leaf node represents a final outcome. \n",
    "\n",
    "\n",
    "Now, you can do various things with these components of decision trees : \n",
    "\n",
    "- Pruning : It refers to cutting down nodes/branches that do not provide any additional information or value for the purpose of preventing model overfitting.\n",
    "\n",
    "<img src = \"https://upload.wikimedia.org/wikipedia/commons/2/23/Before_after_pruning.png\" height = 200px>\n",
    "\n",
    "- Splitting : Splitting a decision tree refers to the process of creating branches or sub-trees from a decision node. The act of splitting is done depending on the features, dataset and problem at hand.\n",
    "\n",
    "<img src = \"https://i.ytimg.com/vi/gqlWi4HjRYI/maxresdefault.jpg\" height = 300px>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that decision trees follow a [Sum-of-Product](https://www.electronics-tutorials.ws/boolean/sum-of-product.html) or Disjunctive Normal Form. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Decision Trees work?\n",
    "\n",
    "The main motive of a decision tree classifier is to select which attributes or features it needs to make a decision upon, or make them a root node. There are several methods to do this and these are called \"Attribute Selection Measures\" or ASM. ASM can be understood as metrics that help define the usefulness of a feature while we split the dataset for decision-making. This is usually done by gauging the amount of raw information a feature provides in relation with a target variable. \n",
    "\n",
    "Decision trees aim to maximize the information gained while splitting the data - this means if the data is correctly split - the groups that the data is split into will become more and more homogenous. A decision tree algorithm repeats this process of splitting till an acceptable level of homogenity is reached allowing the algorithm to classify unknown data points into correct classes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

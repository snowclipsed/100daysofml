# 100 Days of Machine Learning

Hey there, this repository is made in an effort to track my contributions towards the [*#100daysofml*](https://twitter.com/search?q=%23100daysofMLCode&src=hashtag_click) challenge!

It might take some time to format the notebooks and upload them, but I will be updating my progress on [Twitter](https://twitter.com/snowclipsed).
<br> 

I will be hosting all the blogs and markdown content on my website soon. Here's a table with my entire progress!

<h3 align = 'center'>⭐ Star this repo if you wanna follow my journey!⭐</h3>

| Day | Topics | Blog Notebook | Tweet Link |
| ---- | --- | --------- | ---------- |
| 1    | What is ML? <br> Supervised and Unsupervised ML | [Notebook 1](https://github.com/snowclipsed/100daysofml/blob/main/Day%201/Day%201.ipynb) | [Day 1](https://twitter.com/snowclipsed/status/1659999216561963008?s=20) |
| 2    | EDA, Plots, matplotlib and seaborn, Data cleaning, Correlation matrices and inference, PCA, Linear Regression (started) | [Notebook 2](https://github.com/snowclipsed/100daysofml/blob/main/Day%202/Day%202.ipynb) | [Day 2](https://twitter.com/snowclipsed/status/1660352300492390400?s=20) |
| 3    | Linear Regression (continued from yesterday), Cost functions, MSE | [Notebook 3](https://github.com/snowclipsed/100daysofml/blob/main/Day%203/Day%203.ipynb) | [Day 3](https://twitter.com/snowclipsed/status/1660716344239869952?s=20) |
| 4    | Gradient Descent, Learning Rate, LR Implementation | [Notebook 4](https://github.com/snowclipsed/100daysofml/blob/main/Day%203/Day%203.ipynb) | [Day 4](https://twitter.com/snowclipsed/status/1661080481943928832?s=20) |
| 5    | Multiple LR, SVM, Naive Bayes | [Notebook 5](https://github.com/snowclipsed/100daysofml/blob/main/Day%205/Day%205.ipynb) | [Day 5](https://twitter.com/snowclipsed/status/1661431959242047488?s=20) |
| 6    | Feature Selection basics, accuracy, precision, recall, F1-score,precision vs recall tradeoff | [Notebook 6]() | [Day 6](https://twitter.com/snowclipsed/status/1661803117040766976?s=20) |
| 7    | SVM soft margin and Kernel Trick, Logistic Regression theory and types, KNNs theory | [Notebook 7]() | [Day 7](https://twitter.com/snowclipsed/status/1662168795123965953?s=20) |
| 8    | Decison Trees, Feature Imputation, Feature Encoding | [Notebook 8]() | [Day 8](https://twitter.com/snowclipsed/status/1662536960781717504?s=20) |
| 9    | Decision Trees contd. , Bagging and Boosting, AdaBoost, Random Forests |  [Notebook 9]() | [Day 9](https://twitter.com/snowclipsed/status/1662899550363987969?s=20) |
| 10    | Decision Trees Implemented , Feature Engineering basics, Feature Normalization |  [Notebook 10]() | [Day 10](https://twitter.com/snowclipsed/status/1663256992432132096?s=20) |
| 11    | Revision of Concepts, Feature Engineering Contd. |  [Notebook 11]() | [Day 11](https://twitter.com/snowclipsed/status/1663615985461624832?s=20) |
| 12    | More Decision Tree Implementation, Random Forests basics, XGBoost Basics|  [Notebook 12]() | [Day 12](https://twitter.com/snowclipsed/status/1663987548916711425?s=20) |
| 13    | Revision Day, XGBoost Implemented |  [Notebook 13]() | [Day 13](https://twitter.com/snowclipsed/status/1664343056160817153?s=20) |
| 14    | Intro to Deep Learning , Basics of Perceptron |  [Notebook 14]() | [Day 14](https://twitter.com/snowclipsed/status/1664824493666172929?s=20) |
| 15    | MLP basics, activation function, layers |  [Notebook 15]() | [Day 15](https://twitter.com/snowclipsed/status/1665072205099851776?s=20) |
| 16    | Learning rate, Backpropagation Intuition, Normalization |  [Notebook 16]() | [Day 16](https://twitter.com/snowclipsed/status/1665443154621808645?s=20) |
| 17    | Normalization contd. , Regularization |  [Notebook 17]() | [Day 17](https://twitter.com/snowclipsed/status/1665797393550577665?s=20) |


